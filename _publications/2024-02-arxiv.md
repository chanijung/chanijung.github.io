---
selected: '2.0'
title: 'Translating Subgraphs to Nodes Makes Simple GNNs Strong and Efficient for Subgraph Representation Learning'
authors: 'Dongkwan Kim and Alice Oh'
collection: 'publications'
permalink: '/publications/2024-02-arxiv'
date: '2024-02-06'
venue: 'Arxiv'
type: 'preprint'
summary: '*One-sentence Summary: We propose Subgraph-To-Node translation to effectively and efficiently learn representations of subgraphs by coarsely translating subgraphs into nodes.*'
arxivurl: 'https://arxiv.org/abs/2204.04510v2'
---

Subgraph representation learning has emerged as an important problem, but it is by default approached with specialized graph neural networks on a large global graph. These models demand extensive memory and computational resources but challenge modeling hierarchical structures of subgraphs. In this paper, we propose Subgraph-To-Node (S2N) translation, a novel formulation for learning representations of subgraphs. Specifically, given a set of subgraphs in the global graph, we construct a new graph by coarsely transforming subgraphs into nodes. Demonstrating both theoretical and empirical evidence, S2N not only significantly reduces memory and computational costs compared to state-of-the-art models but also outperforms them by capturing both local and global structures of the subgraph. By leveraging graph coarsening methods, our method outperforms baselines even in a data-scarce setting with insufficient subgraphs. Our experiments on eight benchmarks demonstrate that fined-tuned models with S2N translation can process 183 -- 711 times more subgraph samples than state-of-the-art models at a better or similar performance level.