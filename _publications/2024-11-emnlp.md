---
selected: '4.0'
title: 'Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models'
authors: 'Chani Jung, Dongkwan Kim, Jiho Jin, Jiseon Kim, Yeon Seonwoo, Yejin Choi, Alice Oh, and Hyunwoo Kim'
collection: 'publications'
permalink: '/publications/2024-11-emnlp'
date: '2024-11-12'
venue: 'Empirical Methods in Natural Language Processing (EMNLP)'
type: 'conference'
summary: '*One-sentence Summary: We assess key precursors of Theory of Mind (ToM) in LLMs by perception-augmented ToM benchmarks. We propose PercepToM, a ToM method inspired by our findings of modelsâ€™ strength in perception inference and weakness in perception-to-belief inference.*'
venueurl: 'https://2024.emnlp.org/'
paperurl: 'https://aclanthology.org/2024.emnlp-main.1105/'
arxivurl: 'https://arxiv.org/abs/2407.06004'
---

While humans naturally develop theory of mind (ToM), the capability to understand other people's mental states and beliefs, state-of-the-art large language models (LLMs) underperform on simple ToM benchmarks. We posit that we can extend our understanding of LLMs' ToM abilities by evaluating key human ToM precursors -- perception inference and perception-to-belief inference -- in LLMs. We introduce two datasets, Percept-ToMi and Percept-FANToM, to evaluate these precursory inferences for ToM in LLMs by annotating characters' perceptions on ToMi and FANToM, respectively. Our evaluation of eight state-of-the-art LLMs reveals that the models generally perform well in perception inference while exhibiting limited capability in perception-to-belief inference (e.g., lack of inhibitory control). Based on these results, we present PercepToM, a novel ToM method leveraging LLMs' strong perception inference capability while supplementing their limited perception-to-belief inference. Experimental results demonstrate that PercepToM significantly enhances LLM's performance, especially in false belief scenarios.