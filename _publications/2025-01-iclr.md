---
selected: '1.0'
title: 'Generalizing Weisfeiler-Lehman Kernels to Subgraphs'
authors: 'Dongkwan Kim and Alice Oh'
collection: 'publications'
permalink: '/publications/2025-04-iclr'
date: '2025-01-22'
venue: 'International Conference on Learning Representations (ICLR)'
type: 'conference'
summary: '*One-sentence Summary: We propose WLKS that extends the WL graph kernel to subgraphs, captures high-order structural similarities in k-hop neighborhoods, efficiently outperforming state-of-the-art GNNs.*'
venueurl: 'https://iclr.cc/Conferences/2025'
paperurl: 'https://openreview.net/forum?id=HZgZrtIreg'
arxivurl: 'https://arxiv.org/abs/2412.02181'
codeurl: 'https://github.com/dongkwan-kim/WLKS'
---

Subgraph representation learning has been effective in solving various real-world problems. However, current graph neural networks (GNNs) produce suboptimal results for subgraph-level tasks due to their inability to capture complex interactions within and between subgraphs. To provide a more expressive and efficient alternative, we propose WLKS, a Weisfeiler-Lehman (WL) kernel generalized for subgraphs by applying the WL algorithm on induced $k$-hop neighborhoods. We combine kernels across different $k$-hop levels to capture richer structural information that is not fully encoded in existing models. Our approach can balance expressiveness and efficiency by eliminating the need for neighborhood sampling. In experiments on eight real-world and synthetic benchmarks, WLKS significantly outperforms leading approaches on five datasets while reducing training time, ranging from 0.01x to 0.25x compared to the state-of-the-art.